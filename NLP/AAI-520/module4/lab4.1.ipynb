{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hudsonshimanyula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hudsonshimanyula/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                             Phrase  Sentiment  Label\n",
      "0   1                    Getting nowhere with surplusage         -1      0\n",
      "1   2  But the Court nowhere suggested that it would ...         -1      0\n",
      "2   3  Petitioners objection to shaving his beard cla...         -1      0\n",
      "3   4           That result clashes with everything else         -1      0\n",
      "4   5  the tolerable duration of police inquiries in ...          0      1\n",
      "   ID                                           sentence  label\n",
      "0   1  has done nothing to satisfy the probable-cause...      0\n",
      "1   2  Addressing that question here , the CCA referr...      1\n",
      "2   3                           standards and procedures      1\n",
      "3   4  has no comprehension of why he has been single...      0\n",
      "4   5  an expert , Dr. Woods , who offered the opinio...      2\n"
     ]
    }
   ],
   "source": [
    "#load data set\n",
    "legal_sentences_training_dir = './dataSets/Legal_Sentences_For_Training_With_BERT_With_Label.xlsx'\n",
    "legal_sentences_testing_dir = './dataSets/Testing_Set_Legal_Sentences.xlsx'\n",
    "\n",
    "\n",
    "#display training data as df\n",
    "training_df = pd.read_excel(legal_sentences_training_dir)\n",
    "testing_df = pd.read_excel(legal_sentences_testing_dir)\n",
    "\n",
    "\n",
    "print(training_df.head())\n",
    "print(testing_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the text data (remove stopwords, punctuation, lowercase, etc.).\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "    # Remove words with length less than 3\n",
    "    filtered_text = [word for word in filtered_text if len(word) >= 3]\n",
    "\n",
    "    # Join all\n",
    "    text = \" \".join(filtered_text)\n",
    "\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Phrase  \\\n",
      "0                    Getting nowhere with surplusage   \n",
      "1  But the Court nowhere suggested that it would ...   \n",
      "2  Petitioners objection to shaving his beard cla...   \n",
      "3           That result clashes with everything else   \n",
      "4  the tolerable duration of police inquiries in ...   \n",
      "\n",
      "                                      Cleaned_Phrase  \n",
      "0                         getting nowhere surplusage  \n",
      "1  court nowhere suggested would narrow bivens ex...  \n",
      "2  petitioners objection shaving beard clashes ar...  \n",
      "3                     result clashes everything else  \n",
      "4  tolerable duration police inquiries trafficsto...  \n",
      "                                            sentence  \\\n",
      "0  has done nothing to satisfy the probable-cause...   \n",
      "1  Addressing that question here , the CCA referr...   \n",
      "2                           standards and procedures   \n",
      "3  has no comprehension of why he has been single...   \n",
      "4  an expert , Dr. Woods , who offered the opinio...   \n",
      "\n",
      "                                      Cleaned_Phrase  \n",
      "0     done nothing satisfy probablecause requirement  \n",
      "1  addressing question cca referred moore educati...  \n",
      "2                               standards procedures  \n",
      "3                              comprehension singled  \n",
      "4  expert woods offered opinion mcwilliams suffer...  \n"
     ]
    }
   ],
   "source": [
    "#clean the training sentences\n",
    "cleaned_training_df = training_df['Phrase'].apply(preprocess_text)\n",
    "cleaned_testing_df = testing_df['sentence'].apply(preprocess_text)\n",
    "\n",
    "training_df['Cleaned_Phrase'] = cleaned_training_df\n",
    "testing_df['Cleaned_Phrase'] = cleaned_testing_df\n",
    "\n",
    "#Display only the first 5 rows of the cleaned data\n",
    "print(training_df[['Phrase', 'Cleaned_Phrase']].head())\n",
    "print(testing_df[['sentence', 'Cleaned_Phrase']].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           getting nowhere surplusage\n",
      "1    court nowhere suggested would narrow bivens ex...\n",
      "2    petitioners objection shaving beard clashes ar...\n",
      "3                       result clashes everything else\n",
      "4    tolerable duration police inquiries trafficsto...\n",
      "Name: Phrase, dtype: object\n",
      "  (0, 3354)\t0.5973145577883097\n",
      "  (0, 7413)\t0.5973145577883097\n",
      "  (0, 3351)\t0.5351921506415354\n",
      "  (1, 823)\t0.2677191242715201\n",
      "  (1, 4919)\t0.2677191242715201\n",
      "  (1, 7368)\t0.2677191242715201\n",
      "  (1, 1824)\t0.2677191242715201\n",
      "  (1, 2929)\t0.2677191242715201\n",
      "  (1, 822)\t0.2677191242715201\n",
      "  (1, 4918)\t0.2677191242715201\n",
      "  (1, 7367)\t0.2677191242715201\n",
      "  (1, 1823)\t0.2677191242715201\n",
      "  (1, 6750)\t0.25143169292387396\n",
      "  (1, 2928)\t0.2677191242715201\n",
      "  (1, 821)\t0.2677191242715201\n",
      "  (1, 4917)\t0.2677191242715201\n",
      "  (1, 7364)\t0.23987557647560742\n",
      "  (1, 1749)\t0.13841769249418262\n",
      "  (2, 1699)\t0.1949495842462718\n",
      "  (2, 2159)\t0.1949495842462718\n",
      "  (2, 540)\t0.1949495842462718\n",
      "  (2, 1208)\t0.1949495842462718\n",
      "  (2, 782)\t0.1949495842462718\n",
      "  (2, 6924)\t0.1949495842462718\n",
      "  (2, 5049)\t0.1949495842462718\n",
      "  :\t:\n",
      "  (574, 3088)\t0.22101509858441615\n",
      "  (574, 1394)\t0.22101509858441615\n",
      "  (574, 7749)\t0.22101509858441615\n",
      "  (574, 3764)\t0.22101509858441615\n",
      "  (574, 3085)\t0.2108569670204692\n",
      "  (574, 5089)\t0.20297770804343987\n",
      "  (574, 7956)\t0.2108569670204692\n",
      "  (574, 6448)\t0.2108569670204692\n",
      "  (574, 1209)\t0.16923834122532622\n",
      "  (574, 6447)\t0.2108569670204692\n",
      "  (575, 1205)\t0.2682277286273054\n",
      "  (575, 1535)\t0.2682277286273054\n",
      "  (575, 7105)\t0.2682277286273054\n",
      "  (575, 1484)\t0.2682277286273054\n",
      "  (575, 4659)\t0.2682277286273054\n",
      "  (575, 1204)\t0.2682277286273054\n",
      "  (575, 7104)\t0.2682277286273054\n",
      "  (575, 1483)\t0.2682277286273054\n",
      "  (575, 7103)\t0.2682277286273054\n",
      "  (575, 1533)\t0.2519093549308431\n",
      "  (575, 1201)\t0.2519093549308431\n",
      "  (575, 1532)\t0.2519093549308431\n",
      "  (575, 7309)\t0.2519093549308431\n",
      "  (575, 4654)\t0.2313506354364935\n",
      "  (575, 1470)\t0.21243484044611569\n",
      "['016' '016 higher' '016 higher spend' '109a' '17yearold'\n",
      " '17yearold victim' '17yearold victim qualify' '1934' '1934 outbreak'\n",
      " '1934 outbreak bank']\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_training_df.head())\n",
    "\n",
    "#Perform keyword extraction using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, max_features=200000,\n",
    "                                 min_df=0.0, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=word_tokenize, ngram_range=(1,3))\n",
    "\n",
    "# Fit the vectorizer to training data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_training_df)  \n",
    "\n",
    "# Print the TF-IDF scores\n",
    "print(tfidf_matrix)\n",
    "\n",
    "# Get the feature names (words/terms)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the first 10 features\n",
    "print(feature_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the rating scale into sentiment labels, such as \"positive,\" \"negative,\" and \"neutral.\"\n",
    "# Convert the ratings into sentiment labels\n",
    "def to_sentiment(rating):\n",
    "    rating = int(rating)\n",
    "    if rating == 1:\n",
    "        return \"negative\"\n",
    "    elif rating == 2:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Phrase  Sentiment  \\\n",
      "0                    Getting nowhere with surplusage         -1   \n",
      "1  But the Court nowhere suggested that it would ...         -1   \n",
      "2  Petitioners objection to shaving his beard cla...         -1   \n",
      "3           That result clashes with everything else         -1   \n",
      "4  the tolerable duration of police inquiries in ...          0   \n",
      "5  retrial be tolerable if the trial error could ...          0   \n",
      "6                      I would be inclined to agree.          0   \n",
      "7  the trial court was inclined to accept the pro...          1   \n",
      "8  a plaintiff could overcome these hurdles where...          1   \n",
      "9  the procedural hurdles it could impose before ...         -1   \n",
      "\n",
      "  Sentiment_Label  \n",
      "0        negative  \n",
      "1        negative  \n",
      "2        negative  \n",
      "3        negative  \n",
      "4         neutral  \n",
      "5         neutral  \n",
      "6         neutral  \n",
      "7        positive  \n",
      "8        positive  \n",
      "9        negative  \n"
     ]
    }
   ],
   "source": [
    "#Label as positive, negative, or neutral on training data\n",
    "training_df['Sentiment_Label'] = training_df['Sentiment'].map({-1: 'negative', 0: 'neutral', 1: 'positive'})\n",
    "\n",
    "#Print the first 10 rows\n",
    "print(training_df[['Phrase', 'Sentiment', 'Sentiment_Label']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets.\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, training_df['Sentiment'], test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5948275862068966\n",
      "[[67  0  0]\n",
      " [19  0  0]\n",
      " [28  0  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      1.00      0.74        67\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       1.00      0.07      0.12        30\n",
      "\n",
      "    accuracy                           0.59       116\n",
      "   macro avg       0.53      0.36      0.29       116\n",
      "weighted avg       0.60      0.59      0.46       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Model Training/Buidling\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Model Evaluation\n",
    "# Predict the labels on validation dataset\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5862068965517241\n",
      "[[67  0  0]\n",
      " [19  0  0]\n",
      " [29  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      1.00      0.74        67\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       1.00      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.59       116\n",
      "   macro avg       0.53      0.34      0.27       116\n",
      "weighted avg       0.60      0.59      0.44       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Try SVM and Random Forest\n",
    "\n",
    "# Import the necessary libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on validation dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5862068965517241\n",
      "[[67  0  0]\n",
      " [19  0  0]\n",
      " [28  1  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      1.00      0.74        67\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       1.00      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.59       116\n",
      "   macro avg       0.53      0.34      0.27       116\n",
      "weighted avg       0.60      0.59      0.44       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use svm balanced\n",
    "# Train the model\n",
    "model = SVC(class_weight='balanced')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on validation dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5689655172413793\n",
      "[[66  0  1]\n",
      " [18  0  1]\n",
      " [30  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.99      0.73        67\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.57       116\n",
      "   macro avg       0.19      0.33      0.24       116\n",
      "weighted avg       0.33      0.57      0.42       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Use random forest\n",
    "# Train the model\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on validation dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.0639 - accuracy: 0.4478 - val_loss: 0.9790 - val_accuracy: 0.5776\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.4804 - val_loss: 0.9878 - val_accuracy: 0.5776\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.5326 - val_loss: 0.9943 - val_accuracy: 0.5776\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8113 - accuracy: 0.6630 - val_loss: 0.9937 - val_accuracy: 0.5776\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.8283 - val_loss: 1.0023 - val_accuracy: 0.5690\n",
      "4/4 [==============================] - 0s 813us/step - loss: 1.0023 - accuracy: 0.5690\n",
      "Accuracy: 0.568965494632721\n"
     ]
    }
   ],
   "source": [
    "#Try using neural network\n",
    "\n",
    "# Import the necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assume training_df is your training data and 'Cleaned_Phrase' is the text data\n",
    "texts = training_df['Cleaned_Phrase'].values\n",
    "labels = training_df['Sentiment'].values + 1  # This will convert -1 to 0, 0 to 1, and 1 to 2\n",
    "\n",
    "# Tokenization and Padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Building the Neural Network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=data.shape[1]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Assuming 3 sentiment classes: 0, 1, 2 now instead of -1, 0, 1\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_MASTERS_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
