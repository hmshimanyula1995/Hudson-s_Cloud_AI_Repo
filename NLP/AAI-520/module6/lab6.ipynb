{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162421\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 2000)\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "# Load the data\n",
    "file_path = './dataSets/complaints_processed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first 5 rows\n",
    "data.head()\n",
    "\n",
    "data['narrative'] = data['narrative'].astype(str)\n",
    "\n",
    "\n",
    "#Count number of rows in data set\n",
    "print(len(data))\n",
    "\n",
    "#Only use 1000 rows of data\n",
    "data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "#Count number of rows in data set\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hudsonshimanyula/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hudsonshimanyula/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Clean the data\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import string  \n",
    "\n",
    "\n",
    "# It's a good practice to download the necessary NLTK data beforehand\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    filtered_text = [word for word in filtered_text if len(word) >= 3]\n",
    "    text = \" \".join(filtered_text)\n",
    "    return text\n",
    "\n",
    "# Apply the preprocess_text function to the 'narrative' column of your data\n",
    "data['narrative'] = data['narrative'].astype(str).apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156566</th>\n",
       "      <td>156566</td>\n",
       "      <td>mortgages_and_loans</td>\n",
       "      <td>penfed asking copy driver license finalizing loan american customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1498</td>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>collection account removed credit report franklin collection service credit score increase removal collection account credit report increased credit score least point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134991</th>\n",
       "      <td>134991</td>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>bureau falsely reporting alleged debt fdcpa section violation usc alleged debt verified yet receive response day another violation fcra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56391</th>\n",
       "      <td>56391</td>\n",
       "      <td>mortgages_and_loans</td>\n",
       "      <td>mortgage well fargo bank since meet condition streamline refinance filed refi application provided documentation requested immediately online updated document month dragged foot kept asking documentation rate lock extended expires rate lock extended numerous time law firm closing trying get give date closing provide date given asked month ago representative well fargo explain low interest rate swamped refinances therefore behind month plus received loan estimate told loan passed final underwriting approval known date close point rate lock expires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9067</th>\n",
       "      <td>9067</td>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>bank xxxxi credit card mine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0              product  \\\n",
       "156566      156566  mortgages_and_loans   \n",
       "1498          1498     credit_reporting   \n",
       "134991      134991     credit_reporting   \n",
       "56391        56391  mortgages_and_loans   \n",
       "9067          9067     credit_reporting   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       narrative  \n",
       "156566                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       penfed asking copy driver license finalizing loan american customer  \n",
       "1498                                                                                                                                                                                                                                                                                                                                                                                                      collection account removed credit report franklin collection service credit score increase removal collection account credit report increased credit score least point  \n",
       "134991                                                                                                                                                                                                                                                                                                                                                                                                                                   bureau falsely reporting alleged debt fdcpa section violation usc alleged debt verified yet receive response day another violation fcra  \n",
       "56391   mortgage well fargo bank since meet condition streamline refinance filed refi application provided documentation requested immediately online updated document month dragged foot kept asking documentation rate lock extended expires rate lock extended numerous time law firm closing trying get give date closing provide date given asked month ago representative well fargo explain low interest rate swamped refinances therefore behind month plus received loan estimate told loan passed final underwriting approval known date close point rate lock expires  \n",
       "9067                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 bank xxxxi credit card mine  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the first 5 rows of your data to make sure the preprocessing happened correctly\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "inputs = tokenizer(data['narrative'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "labels = torch.tensor(data['product'].astype('category').cat.codes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
    "    inputs['input_ids'], labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create torch DataLoaders for training and testing data\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_labels)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_labels = data['product'].nunique()\n",
    "print(num_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 25/25 [12:24<00:00, 29.76s/it]\n",
      "Epoch 2: 100%|██████████| 25/25 [12:15<00:00, 29.43s/it]\n",
      "Epoch 3: 100%|██████████| 25/25 [12:16<00:00, 29.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "# Define the training parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    epoch_loss = 0  # Initialize the epoch loss\n",
    "    # Wrap your dataloader with tqdm to show a progress bar\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, labels = batch\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()  # Update the epoch loss\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "for batch in test_dataloader:\n",
    "    input_ids, labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1).tolist()\n",
    "    predictions.extend(predicted_labels)\n",
    "    true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.00%\n",
      "Precision: 44.26%\n",
      "Recall: 58.00%\n",
      "F1 Score: 49.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonshimanyula/anaconda3/envs/AI_MASTERS_ENV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "print(f'Precision: {precision*100:.2f}%')\n",
    "print(f'Recall: {recall*100:.2f}%')\n",
    "print(f'F1 Score: {f1*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_MASTERS_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
